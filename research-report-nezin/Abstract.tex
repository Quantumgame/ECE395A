\section{Abstract}
In addition to the size, weight, power, and latency advantages offered by FPGA's, they have also drawn attention in deep learning applications for their reconfigurability from large companies like Microsoft.~\cite{Putnam:2014:RFA:2665671.2665678} Google has also recently developed specialized hardware for deep learning performance enhancement in the form of the "Tensor Processing Unit" (TPU).  The TPU was originally planned to be an FPGA when "[Google] saw that the FPGAs of that time were not competitive in performance compared to the GPUs of that time."~\cite{DBLP:journals/corr/JouppiYPPABBBBB17}  In spite of their apparent lack of power, FPGAs have recently drawn a large amount of attention in the deep learning community and significant work has been done into putting neural nets onto FPGAs.  In this document we will look at previous work done in optimizing hardware design for neural nets and optimizing neural nets for hardware design.  

All of this will be a means to an end.  In order to take advantage of the strengths of both neural nets and FPGAs we want to demonstrate our technology toward solving a problem which requires high accuracy, low latency, and possibly low power.
Wireless modulation classification has been, and continues to be an important engineering problem.  
Sensing and classifying wireless signals is relevant to applications including government spectrum regulation, cognitive radio, and situational awareness in military/adversarial environments.  ~\cite{DBLP:journals/corr/RajendranCFBCGP17}  Deep neural networks have recently achieved impressive performance in classifying audio, images, and video.  The application of neural networks to wireless communication has recently grown in the machine learning community.  Applications include nonlinear channel modeling, learned data encoding, and modulation classification.  ~\cite{DBLP:journals/corr/OSheaH17}  While promising results have been achieved, they have only been implemented on graphics processing units (GPUs) which have relatively large size, weight, power, and latency compared to FPGAs. ~\cite{Nurvitadhi:2017:FBG:3020078.3021740} 
